eval:
  defaults:
    n_samples_per_eval_prompt: 1
    # temperature: 0.6
    top_p: 0.95
    top_k: -1
    max_response_len: 24576
  datasets: # minimal smoke eval to keep eval-only path happy
    - name: smoke
      path: /mnt/data/zhiyao/tb_evaluation/tb_eval_smoke/eval_smoke.jsonl
      rm_type: deepscaler
  # datasets: # these eval tasks go through slime dataset config and default rollout function (slime.rollout.sglang_rollout.generate_rollout)
    # - name: gpqa    # huggingface-cli download --repo-type dataset zyzshishui0627/gpqa_diamond --local-dir /root/gpqa
    #   path: /root/gpqa/gpqa_eval.jsonl
    #   rm_type: gpqa
    #   n_samples_per_eval_prompt: 2
    # - name: ifbench   # huggingface-cli download --repo-type dataset zyzshishui0627/IFBench --local-dir /root/ifbench
    #   path: /root/ifbench/IFBench_eval.jsonl
    #   rm_type: ifbench
    #   n_samples_per_eval_prompt: 1
  delegate: # these tasks go through delegate eval function (examples.eval.eval_delegate_rollout.generate_rollout)
    # - name: skills 
    #   # this url should align with env docker network alias
    #   url: http://skills_server:9050/evaluate
    #   timeout_secs: 7200
    #   max_retries: 5
    #   headers: {}
    #   datasets:
    #     - name: aime25
    #       max_response_len: 8192
    #       n_samples_per_eval_prompt: 8
    #     - name: arena-hard
    #       n_samples_per_eval_prompt: 2
    #     - name: hle
    #       max_response_len: 32768
    - name: tb
      url: http://127.0.0.1:9060/evaluate
      model_name: openai/qwen3-8b
      api_base: http://127.0.0.1:30002/v1
      n_concurrent: 8
      n_tasks: 1
      task_ids:
        - hello-world